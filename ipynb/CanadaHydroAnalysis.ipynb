{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Part I: Importing Libraries and retrieval/download of files from GovCanada webpage\n",
    "\n",
    "* *Part I running time: ~20 mins*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T04:04:17.185088Z",
     "start_time": "2021-08-03T04:04:12.302480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import timeit, time libraries and start clock \n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# datetime timer\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# Data analysis \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Web scraping and file retrieval\n",
    "import os\n",
    "import glob\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import wget\n",
    "\n",
    "# Database processing\n",
    "import sqlite3\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Visualization and geo-data imports\n",
    "import geopandas as gpd\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "#import plotly.edf_masterpress as pdf_master\n",
    "\n",
    "# Offline mode\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Hyperlink / Web display\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Formatting options\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print('Library imports complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Hydrometric Station Location data from Hydat.sqlite3 database\n",
    "\n",
    "* *Select STATIONS where HYD_STATUS = A (Active)*\n",
    "* *Ignore STATIONS where HYD_STATUS = D (Deactivated/Inactive)*\n",
    "* *Export the database table to a .csv file*\n",
    "* *Check the file DataFrame file to see that it works!*\n",
    "* *Close the connection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T04:04:17.310752Z",
     "start_time": "2021-08-03T04:04:17.220992Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/sqlite3')\n",
    "\n",
    "# Create connection to Hydat database\n",
    "con = sqlite3.connect(\"Hydat.sqlite3\")\n",
    "cursor = con.cursor()\n",
    "\n",
    "#all_database_stuff = cursor.execute(\"SELECT * FROM sqlite_master\").fetchall()\n",
    "df_stations = pd.read_sql_query('SELECT * from STATIONS where HYD_STATUS = \"A\"', con) #A = active stations\n",
    "\n",
    "# Verify that result of SQL query is stored in the dataframe\n",
    "df_stations.rename(columns={df_stations.columns[0]: \"ID\"}, inplace=True)\n",
    "df_stations.rename(columns={df_stations.columns[2]: \"PROV_TERR\"}, inplace=True)\n",
    "df_stations.rename(columns={df_stations.columns[8]: \"DRAINAGE_AREA_GROSS_KM2\"}, inplace=True)\n",
    "\n",
    "df_stations['PROV_TERR_ID'] = df_stations['PROV_TERR'] + df_stations['ID']\n",
    "\n",
    "# Drop extra columns \n",
    "df_stations.drop(labels = ['DRAINAGE_AREA_EFFECT','DATUM_ID','SED_STATUS'], inplace=True, axis=1)\n",
    "\n",
    "print(df_stations.info())\n",
    "\n",
    "df_stations.to_csv('HYDAT.csv', encoding='utf-8')\n",
    "\n",
    "# Close the connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "## Download multiple .csv files from Hydrometric .url directory using wget\n",
    "\n",
    "* *Hyperlink:* <a href=\"https://dd.weather.gc.ca/hydrometric/csv/\">[https://dd.weather.gc.ca/hydrometric/csv/](https://dd.weather.gc.ca/hydrometric/csv/)</a>\n",
    "\n",
    "* *Downloading time: ~4 mins*\n",
    "\n",
    "* *All provincial files for download:*\n",
    "\n",
    "    \"AB_daily_hydrometric.csv, BC_daily_hydrometric.csv, SK_daily_hydrometric.csv, /\n",
    "    MB_daily_hydrometric.csv, ON_daily_hydrometric.csv, QC_daily_hydrometric.csv, /\n",
    "    NB_daily_hydrometric.csv, NS_daily_hydrometric.csv, PE_daily_hydrometric.csv, /\n",
    "    NL_daily_hydrometric.csv, NT_daily_hydrometric.csv, NU_daily_hydrometric.csv, /\n",
    "    YT_daily_hydrometric.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily\")\n",
    "\n",
    "# Download hydrometric daily sub directories fast:\n",
    "!wget --wait=2 -r -np -nH -nd -e robots=off --cut-dirs=3 --reject \"index.html*\" --accept \"AB_daily_hydrometric.csv, BC_daily_hydrometric.csv, SK_daily_hydrometric.csv, MB_daily_hydrometric.csv, ON_daily_hydrometric.csv, QC_daily_hydrometric.csv, NB_daily_hydrometric.csv, NS_daily_hydrometric.csv, PE_daily_hydrometric.csv, NL_daily_hydrometric.csv, NT_daily_hydrometric.csv, NU_daily_hydrometric.csv, YT_daily_hydrometric.csv\" https://dd.weather.gc.ca/hydrometric/csv/ --no-check-certificate\n",
    "\n",
    "# Template for file downloads\n",
    "\"\"\"\n",
    "\"AB_daily_hydrometric.csv, BC_daily_hydrometric.csv, SK_daily_hydrometric.csv, /\n",
    "MB_daily_hydrometric.csv, ON_daily_hydrometric.csv, QC_daily_hydrometric.csv, /\n",
    "NB_daily_hydrometric.csv, NS_daily_hydrometric.csv, PE_daily_hydrometric.csv, /\n",
    "NL_daily_hydrometric.csv, NT_daily_hydrometric.csv, NU_daily_hydrometric.csv, /\n",
    "YT_daily_hydrometric.csv\"\n",
    "\n",
    "\"\"\"\n",
    "print(\"Completed downloads!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Part II: Concatenate (Combine) all provincial DAILY .csv files into one DAILY .csv file\n",
    "\n",
    "* *Runtime ~4 mins*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print all .csv files in CanadaDaily directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Web scraping and file retrieval\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Change the directory to /CanadaDaily\n",
    "os.chdir(r\"C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily\")\n",
    "\n",
    "# Use glob to match the pattern '.csv'\n",
    "ext = '.csv'\n",
    "fnames = [i for i in glob.glob('*{}'.format(ext))]\n",
    "print(fnames)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat all provincial .csv file together and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all files in the list and export as .csv\n",
    "print('Concatenating all provincial daily hydrometric files into national file..\\n')\n",
    "\n",
    "dtypes = {\" ID\": str,\n",
    "          \"Date\": str, \n",
    "          \"Water Level / Niveau d'eau (m)\": np.float32, \n",
    "          \"Discharge / DÃ©bit (cms)\": np.float32}\n",
    "          \n",
    "cols = list(dtypes.keys())\n",
    "\n",
    "path = r\"C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily\"\n",
    "df_daily = pd.concat((pd.read_csv(f, usecols=cols, dtype=dtypes,\n",
    "                                  sep=',', low_memory=False) for f in fnames))\n",
    "\n",
    "# Cleanup new file (rename and fill N/A values)\n",
    "column_indices = [0, 1, 2, 3]\n",
    "new_names = [\"ID\", \"DATE\", \"WATER_LEVEL_M\", \"FLOWRATE_CMS\"]\n",
    "old_names = df_daily.columns[column_indices]\n",
    "df_daily.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "\n",
    "# Fill N/A values\n",
    "df_daily.fillna(value='', inplace=True)\n",
    "\n",
    "# Merge the DAILY DataFrame with the HYDRO STATION DATABASE DataFrame\n",
    "df_daily = pd.merge(df_daily, df_stations, on='ID')\n",
    "\n",
    "cols = [\"WATER_LEVEL_M\", \"FLOWRATE_CMS\", \"LATITUDE\", \"LONGITUDE\", \"DRAINAGE_AREA_GROSS_KM2\"]\n",
    "df_daily[cols] = pd.to_numeric(df_daily[cols].stack(), errors='coerce', downcast='float').unstack()\n",
    "\n",
    "df_daily['STATION'] = df_daily['PROV_TERR_ID'] + \"_\" + df_daily['STATION_NAME']\n",
    "\n",
    "# Replace blank spaces with _\n",
    "df_daily['STATION'] = df_daily['STATION'].str.replace(' ', '_')\n",
    "df_daily['STATION'] = df_daily['STATION'].str.replace('//', '_')\n",
    "df_daily['STATION'] = df_daily['STATION'].str.replace('\\\\', '_')\n",
    "\n",
    "# Drop unneeded columns\n",
    "df_daily.drop(columns=['PROV_TERR_ID', 'REGIONAL_OFFICE_ID', 'HYD_STATUS', 'STATION_NAME'], inplace=True)\n",
    "\n",
    "# Sample data on hourly basis\n",
    "df_daily.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Create and Clean Master DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Clean Master DataFrame (CAN_daily_hydrometric_master.csv)\n",
    "\n",
    "- Read in the MASTER df using Dask\n",
    "- Concat both DataFrames on the DATE column. This adds the newest dates to the MASTER df.\n",
    "- Convert all numeric values to float32 and convert DATE column to datetime64[ns, utc] format.\n",
    "- Compare the lengths of the DAILY df and the MASTER df\n",
    "- Export the new MASTER df to .csv and overwrite the old MASTER .csv file\n",
    "\n",
    "**Notes:**\n",
    "     \n",
    "* *The .csv file will continue to grow and is easiest to process using Dask for in-memory processing\n",
    "  as processing memory above 16GB can be selected*\n",
    "\n",
    "* *To save time and money, multiple VMs (Virtual Machine) such as Amazon EC2 or Microsoft Azure VM\n",
    "  are the fastest method to plug into big computing power. Only consider this for very large real-time \n",
    "  datasets as it becomes pricey depending on the size of the datasets (GB, TB, PB, etc.)*\n",
    " \n",
    "* *Runtime ~ 6 mins*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "# If Master file exists in filepath..\n",
    "if os.path.isfile(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily/og/CAN_daily_hydrometric_master.parquet'):\n",
    "    \n",
    "    print(\"File exists! Merge Daily DataFrame with Master DataFrame..\")\n",
    "\n",
    "    f = r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily/og/CAN_daily_hydrometric_master.parquet'\n",
    "\n",
    "    # Import the new MASTER.csv as a DataFrmae and follow same cleaning process as above.\n",
    "    df_master = pd.read_parquet(f, engine='pyarrow') # Process in 100MB chunk\n",
    "\n",
    "    # Replace all NaN (null and N/A) numeric columns with np.NaN value\n",
    "    float_cols_na = ['WATER_LEVEL_M', \n",
    "                     'FLOWRATE_CMS', \n",
    "                     'LATITUDE', \n",
    "                     'LONGITUDE', \n",
    "                     'DRAINAGE_AREA_GROSS_KM2']\n",
    "    \n",
    "    df_master[float_cols_na] = df_master[float_cols_na].replace({'NaN': np.nan})\n",
    "\n",
    "    # Drop all null rows\n",
    "    df_master.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    print('Merge master and daily DataFrames. Add newest DATE rows to the master DataFrame..')\n",
    "    df_final = pd.concat([df_master, df_daily], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    df_final['DATE'] = pd.to_datetime(df_final['DATE'], errors='coerce', utc=True)\n",
    "    df_final = df_final.resample('H', on='DATE', axis=0)\n",
    "    \n",
    "    print('Export Master DataFrame to .csv format..')\n",
    "    os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily/og')\n",
    "    \n",
    "    master_csv_file = r'CAN_daily_hydrometric_master.csv'\n",
    "    df_final.to_csv(master_csv_file, encoding='utf-8')\n",
    "    \n",
    "    master_parq_file = r'CAN_daily_hydrometric_master.parquet'\n",
    "    df_final.to_parquet(master_parq_file, engine='pyarrow')\n",
    "    \n",
    "    len_df_daily = len(df_daily)\n",
    "    len_df_final = len(df_final)\n",
    "\n",
    "    print(f'Daily DataFrame length: {len_df_daily} \\n')\n",
    "    print(f'Master DataFrame length: {len_df_final} \\n')\n",
    "    \n",
    "    print(df_final.head())\n",
    "   \n",
    "else:  \n",
    "        \n",
    "    print('CAN_daily_hydrometric_master file does not exist! Create Master .csv file...')\n",
    "    \n",
    "    # Replace all NaN (null and N/A) numeric columns with np.NaN value\n",
    "    float_cols = [\"FLOWRATE_CMS\", \n",
    "                  \"WATER_LEVEL_M\", \n",
    "                  \"DRAINAGE_AREA_GROSS_KM2\", \n",
    "                  \"LATITUDE\", \n",
    "                  \"LONGITUDE\"]\n",
    "\n",
    "    df_daily[float_cols] = df_daily[float_cols].replace({'NaN': np.nan})\n",
    "\n",
    "    # Drop all null rows\n",
    "    df_daily.dropna(axis=0, inplace=True)\n",
    "     \n",
    "    print(\"Master DataFrame and master .csv file created!\")\n",
    "\n",
    "    print(df_daily.head())\n",
    "    \n",
    "    # Export DataFrame to .csv (named master)\n",
    "    os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily/og')\n",
    "\n",
    "    # Create new MASTER.csv file from DAILY DataFrame\n",
    "    master_csv_file = r\"CAN_daily_hydrometric_master.csv\"\n",
    "    df_daily.to_csv(master_csv_file, encoding='utf-8')\n",
    "    \n",
    "    master_parq_file = r'CAN_daily_hydrometric_master.parquet'\n",
    "    df_daily.to_parquet(master_parq_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete individual provincial .csv files in CanadaDaily directory   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Delete all provincial .csv files\n",
    "for CleanUp in glob.glob(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily/*.*'):\n",
    "    print(f'Files in CanadaDaily folder: {CleanUp}')\n",
    "    \n",
    "    if CleanUp.endswith('.csv'):    \n",
    "        os.remove(CleanUp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of final files\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* **Canadian Daily Hydrometric Stations: CAN_daily_hydrometric.csv**\n",
    "   \n",
    "   * *Location: C:/Users/pdudar/anaconda3/projects/CanadaWatQual/CanadaDaily*         \n",
    "  \n",
    "   \n",
    "* **Canadian Daily Hydrometric Stations (MASTER): CAN_daily_hydrometric.master.csv**\n",
    "   \n",
    "   * *Location: C:/Users/pdudar/anaconda3/projects/CanadaWatQual/CanadaDaily/og*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Plotly Chart generation\n",
    "\n",
    "## Create Hydrometric Daily Plotly Time Series Charts\n",
    "\n",
    "* *Create .html charts for all Hydrometric Stations across Canada*\n",
    "* *Discharge/Flow Rate (cms) is displayed on LEFT side of chart*\n",
    "* *Water Level (m) is displayed on RIGHT side of chart*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_file_path = r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily/og/CAN_daily_hydrometric_master.parquet'\n",
    "\n",
    "if os.path.isfile(master_file_path):\n",
    "    \n",
    "    os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily/og')\n",
    "    \n",
    "    from plotly import __version__ \n",
    "    import cufflinks as cf \n",
    "    from plotly.offline import init_notebook_mode, iplot \n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # to get the connection \n",
    "    init_notebook_mode(connected = True) \n",
    "\n",
    "    # Set Plotly to offline mode\n",
    "    cf.go_offline \n",
    "\n",
    "    f = r'CAN_daily_hydrometric_master.parquet'\n",
    "    df_master = pd.read_parquet(f, engine='pyarrow')\n",
    "    \n",
    "    # Create df by PROVINCE\n",
    "    d_plotly = dict(tuple(df_master.groupby(['STATION'])))\n",
    "\n",
    "    os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly')\n",
    "\n",
    "    k = 1\n",
    "    l = 0\n",
    "    len_stations = len(df_master.STATION.unique())\n",
    "\n",
    "    convert = float(3.0 * 0.0167) # Seconds to minutes\n",
    "    chart_time = convert * len_stations\n",
    "\n",
    "    print(f'Number of charts to create: {len_stations}')\n",
    "    print(f'Chart processing time: {chart_time} minutes')\n",
    "\n",
    "    ##### ----- Make Plotly Time Series Charts ----- #####\n",
    "    from plotly import __version__ \n",
    "    import cufflinks as cf \n",
    "    from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # to get the connection \n",
    "    init_notebook_mode(connected = True) \n",
    "\n",
    "    # plotly also serves online, \n",
    "    # but we are using just a sample \n",
    "    cf.go_offline \n",
    "\n",
    "    print('Creating Plotly charts.. \\n')\n",
    "\n",
    "    d_plotly = dict(tuple(df_master.groupby(['STATION'])))\n",
    "\n",
    "    k = 1\n",
    "    l = 0\n",
    "    len_stations = len(df_master.STATION.unique())\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    for key in d_plotly.keys():\n",
    "        d_plotly[key] = df_master[:][df_master.STATION == key]\n",
    "        df_export_plotly = d_plotly[key]\n",
    "\n",
    "        # Create figure with secondary y-axis\n",
    "        subfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "        # Generate a Plotly TimeSeries chart for each monitoring station\n",
    "        fig = px.line(df_export_plotly, \n",
    "                        x = 'DATE',\n",
    "                        y = 'FLOWRATE_CMS',\n",
    "                        title=key + ': ' + 'Canada Hydrometric Flow Data - Time Series Info',\n",
    "                        hover_name = 'STATION', \n",
    "                        hover_data = ['FLOWRATE_CMS',\n",
    "                                      'LATITUDE',\n",
    "                                      'LONGITUDE',\n",
    "                                      'DRAINAGE_AREA_GROSS_KM2']         \n",
    "                        )\n",
    "\n",
    "        fig2 = px.line(df_export_plotly, \n",
    "                        x='DATE',\n",
    "                        y='WATER_LEVEL_M', \n",
    "                        hover_name = 'STATION', \n",
    "                        hover_data = ['WATER_LEVEL_M',\n",
    "                                      'LATITUDE',\n",
    "                                      'LONGITUDE',\n",
    "                                      'DRAINAGE_AREA_GROSS_KM2']\n",
    "                                   \n",
    "                        )\n",
    "           \n",
    "        fig2.update_traces(yaxis=\"y2\")\n",
    "\n",
    "        subfig.add_traces(fig.data + fig2.data)\n",
    "        subfig.layout.xaxis.title=\"Date\"\n",
    "        subfig.layout.yaxis.title=\"Flowrate (cms)\"\n",
    "        subfig.layout.yaxis2.type=\"linear\"\n",
    "        subfig.layout.yaxis2.title=\"Water Level (m)\"\n",
    "\n",
    "        # recoloring is necessary otherwise lines from fig und fig2 would share each color\n",
    "        # e.g. Linear-, Log- = blue; Linear+, Log+ = red... we don't want this\n",
    "        subfig.for_each_trace(lambda t: t.update(line=dict(color=t.marker.color))) \n",
    "\n",
    "        # Add figure title\n",
    "        subfig.update_layout(\n",
    "            title_text= key + ': ' + 'Canada Hydrometric Flow Data - Time Series Info'\n",
    "        )\n",
    "\n",
    "        # Set y-axes titles\n",
    "        subfig.update_yaxes(title_text=\"<b>Flow Rate (cms)</b>\", secondary_y=False)\n",
    "        subfig.update_yaxes(title_text=\"<b>Water Level (m)</b>\", secondary_y=True)\n",
    "\n",
    "        subfig.update_xaxes(\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1, label=\"1DAY\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=7, label=\"1WK\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=14, label=\"2WK\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1MNTH\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=3, label=\"3MNTH\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6MNTH\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                    dict(count=1, label=\"1YR\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Chart colors\n",
    "        subfig.update_layout(plot_bgcolor = \"RGB(45,45,48)\")  \t#2d2d30\n",
    "        subfig.update_layout(paper_bgcolor = \"RGB(37,37,38)\") #252526\n",
    "\n",
    "        subfig.update_layout(\n",
    "        font_color=\"RGB(131,148,150)\",  \t#839496\n",
    "        title_font_color=\"RGB(131,148,150)\",  \t#839496\n",
    "        legend_title_font_color=\"RGB(131,148,150)\") #839496\n",
    "\n",
    "        # Append station names to .html files\n",
    "        subfig.write_html(key + '.html', include_plotlyjs='cdn')\n",
    "\n",
    "        print('{} seconds: Completed {} plotly charts!'.format((datetime.datetime.now() - start).seconds, k))\n",
    "        if l == len_stations:\n",
    "            break\n",
    "        else:\n",
    "            l+=1\n",
    "\n",
    "        k+=1\n",
    "\n",
    "    print('Plotly charts completed! Charts saved in following '\n",
    "        'directory: /CanadaWatQual/plotly')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDaily')\n",
    "\n",
    "\n",
    "    # Set Plotly to offline mode\n",
    "    cf.go_offline \n",
    "    \n",
    "\n",
    "    d_plotly = dict(tuple(df_daily.groupby(['STATION'])))\n",
    "\n",
    "    os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/CanadaDailyHydrometricHydrometricPlotly')\n",
    "\n",
    "    k = 1\n",
    "    l = 0\n",
    "    len_stations = len(df_daily.STATION.unique())\n",
    "\n",
    "    convert = float(3.0 * 0.0166667)\n",
    "    chart_time = convert * len_stations\n",
    "\n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "    print(f'Number of charts to create: {len_stations}')\n",
    "    print(f'Chart processing time: {chart_time} minutes.')\n",
    "\n",
    "    os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly')\n",
    "\n",
    "    pd.options.display.float_format = '{:,.1f}'.format\n",
    "    \n",
    "    ##### ----- Make Plotly Time Series Charts ----- #####\n",
    "    from plotly import __version__ \n",
    "    import cufflinks as cf \n",
    "    from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    # Create figure with secondary y-axis\n",
    "    fig_ii = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # to get the connection \n",
    "    init_notebook_mode(connected = True) \n",
    "\n",
    "    # plotly also serves online, \n",
    "    # but we are using just a sample \n",
    "    cf.go_offline \n",
    "\n",
    "    print('Creating Plotly charts..\\n')\n",
    "\n",
    "    d_plotly = dict(tuple(df_daily.groupby(['STATION'])))\n",
    "\n",
    "    k = 1\n",
    "    l = 0\n",
    "    len_stations = len(df_daily.STATION.unique())\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    for key in d_plotly.keys():\n",
    "        d_plotly[key] = df_daily[:][df_daily.STATION == key]\n",
    "        df_export_plotly = d_plotly[key]\n",
    "\n",
    "        # Create figure with secondary y-axis\n",
    "        subfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "        # Generate a Plotly TimeSeries chart for each monitoring station\n",
    "        fig = px.line(df_export_plotly, \n",
    "                        x = 'DATE',\n",
    "                        y = 'FLOWRATE_CMS',\n",
    "                        title=key + ': ' + 'Canada Hydrometric Flow Data - Time Series with Range Slider: 2000-present',\n",
    "                        hover_name = 'STATION', \n",
    "                        hover_data = [\n",
    "                                    'FLOWRATE_CMS',\n",
    "                                    'DATE',\n",
    "                                    'LATITUDE',\n",
    "                                    'LONGITUDE',\n",
    "                                    'DRAINAGE_AREA_GROSS_KM2']\n",
    "                        )\n",
    "\n",
    "        fig2 = px.line(df_export_plotly, \n",
    "                        x='DATE',\n",
    "                        y='WATER_LEVEL_M', \n",
    "                        hover_name = 'STATION', \n",
    "                        hover_data = [\n",
    "                                    'WATER_LEVEL_M',\n",
    "                                    'DATE',\n",
    "                                    'LATITUDE',\n",
    "                                    'LONGITUDE',\n",
    "                                    'DRAINAGE_AREA_GROSS_KM2']\n",
    "                        )\n",
    "        \n",
    "        fig2.update_traces(yaxis=\"y2\")\n",
    "    \n",
    "        subfig.add_traces(fig.data + fig2.data)\n",
    "        subfig.layout.xaxis.title=\"Date\"\n",
    "        subfig.layout.yaxis.title=\"Discharge/Flow Rate (cms)\"\n",
    "        subfig.layout.yaxis2.type=\"linear\"\n",
    "        subfig.layout.yaxis2.title=\"Water Level (m)\"\n",
    "          \n",
    "        fig2.update_traces(yaxis=\"y2\")\n",
    "\n",
    "        subfig.add_traces(fig.data + fig2.data)\n",
    "        subfig.layout.xaxis.title=\"Date\"\n",
    "        subfig.layout.yaxis.title=\"Discharge/Flow Rate (cms)\"\n",
    "        subfig.layout.yaxis2.type=\"linear\"\n",
    "        subfig.layout.yaxis2.title=\"Water Level (m)\"\n",
    "\n",
    "        # recoloring is necessary otherwise lines from fig und fig2 would share each color\n",
    "        # e.g. Linear-, Log- = blue; Linear+, Log+ = red... we don't want this\n",
    "        subfig.for_each_trace(lambda t: t.update(line=dict(color=t.marker.color))) \n",
    "\n",
    "        # Add figure title\n",
    "        subfig.update_layout(\n",
    "            title_text= key + ': ' + 'Canada Hydrometric Flow Data - Time Series with Range Slider: 2021-present'\n",
    "        )\n",
    "\n",
    "        # Set y-axes titles\n",
    "        subfig.update_yaxes(title_text=\"<b>Discharge/Flow Rate (cms)</b>\", secondary_y=False)\n",
    "        subfig.update_yaxes(title_text=\"<b>Water Level (m)</b>\", secondary_y=True)\n",
    "\n",
    "        subfig.update_xaxes(\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1, label=\"1DAY\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=7, label=\"1WK\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=14, label=\"2WK\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1MNTH\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=3, label=\"3MNTH\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6MNTH\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                    dict(count=1, label=\"1YR\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Chart colors\n",
    "        subfig.update_layout(plot_bgcolor = \"RGB(45,45,48)\")  \t#2d2d30\n",
    "        subfig.update_layout(paper_bgcolor = \"RGB(37,37,38)\") #252526\n",
    "\n",
    "\n",
    "        subfig.update_layout(\n",
    "        font_color=\"RGB(131,148,150)\",  \t#839496\n",
    "        title_font_color=\"RGB(131,148,150)\",  \t#839496\n",
    "        legend_title_font_color=\"RGB(131,148,150)\") #839496\n",
    "\n",
    "        # Append station names to .html files\n",
    "        subfig.write_html(key + '.html', include_plotlyjs='cdn')\n",
    "\n",
    "        print('{} seconds: Completed {} plotly charts..'.format((datetime.datetime.now() - start).seconds, k))\n",
    "        if l == len_stations:\n",
    "            break\n",
    "        else:\n",
    "            l+=1\n",
    "\n",
    "        k+=1\n",
    "\n",
    "    print('Plotly charts completed! Charts saved in following '\n",
    "        'directory: /CanadaWatQual/Hydro/plotly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make provincial subfolders for .html TimeSeries files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_dir = r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly/'\n",
    "html_dir = 'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly/*.html'\n",
    "\n",
    "subfolder_names = ['BC', 'AB', 'SK', \n",
    "                    'MB', 'ON', 'QC',\n",
    "                    'NB', 'PE', 'NS', \n",
    "                    'NL', 'NU', 'NT', \n",
    "                    'YT']\n",
    "\n",
    "for subfolder in subfolder_names:\n",
    "    \n",
    "    # Make pro directories. If they exist already ignore\n",
    "    os.makedirs(os.path.join(source_dir, subfolder), exist_ok=True)\n",
    "    \n",
    "    # Print the subfolder directory names\n",
    "    sub_dir = os.path.join(source_dir, subfolder)\n",
    "    print(sub_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy all .html files from source directory to Provincial Subfolders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly')\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly'\n",
    "\n",
    "# Define subfolder names\n",
    "ab = '/AB'\n",
    "bc = '/BC'\n",
    "sk = '/SK'\n",
    "mb = '/MB'\n",
    "qc = '/QC'\n",
    "ns = '/NS'\n",
    "nt = '/NT'\n",
    "yt = '/YT'\n",
    "nu = '/NU'\n",
    "pe = '/PE'\n",
    "nl = '/NL'\n",
    "nb = '/NB'\n",
    "\n",
    "# Loop and look for all .html files by prov name (AB_....html)\n",
    "# Copy files by name to prov folder\n",
    "for f in source_dir:\n",
    "    if (f.startswith(\"AB\") and f.endswith('.html')): #\n",
    "        shutil.copy(os.path.join(source_dir, f), ab) \n",
    "    elif (f.startswith(\"BC\") and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), bc)\n",
    "    elif (f.startswith(\"SK\")and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), sk)\n",
    "    elif (f.startswith(\"MB\")and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), mb)\n",
    "    elif (f.startswith(\"QC\")and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), qc)\n",
    "    elif (f.startswith(\"NS\") and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), ns)\n",
    "    elif (f.startswith(\"NT\") and f.endswith('.html') ):\n",
    "        shutil.copy(os.path.join(source_dir, f), nt)\n",
    "    elif (f.startswith(\"NU\")and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), yt)\n",
    "    elif (f.startswith(\"PE\")and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), yt)\n",
    "    elif (f.startswith(\"NL\")and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), yt)\n",
    "    elif (f.startswith(\"NB\")and f.endswith('.html')):\n",
    "        shutil.copy(os.path.join(source_dir, f), yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete original .html files from source directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete original .html files from source directory        \n",
    "dir_path = r'C:\\Users\\pdudar\\anaconda3\\projects\\CanadaWatQual\\Hydro\\plotly'\n",
    "folder = os.listdir(dir_path)\n",
    "\n",
    "for item in folder:\n",
    "    if item.endswith(\".html\"):\n",
    "        os.remove(os.path.join(dir_path, item))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all Provincial subfolders to .zip format\n",
    "\n",
    "- Compress each .zip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import shutil\n",
    "\n",
    "reports_path  = r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly'\n",
    "\n",
    "def zip_prov_folders(reports_path):\n",
    "    for (path, dirs, files) in os.walk(reports_path):\n",
    "        for d in dirs:\n",
    "            file_path = os.path.join(path, d)\n",
    "            print('Compressing: ' + d )\n",
    "            shutil.make_archive(d,'zip', file_path)\n",
    "    print(\"Completed zipping! \\n\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    zip_prov_folders(reports_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete empty folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import shutil\n",
    "\n",
    "folder_location  = r'C:/Users/pdudar/anaconda3/projects/CanadaWatQual/Hydro/plotly'\n",
    "def delete_empty_folders(folder_location):\n",
    "    all_directories = list(os.walk(folder_location))\n",
    "    for path, a, b in all_directories:\n",
    "        if len(os.listdir(path)) == 0:  # Checking if the directory is empty or not\n",
    "            shutil.rmtree(path)         # Delete the folder if it is empty\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    delete_empty_folders(folder_location) #This path is just an example te it\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop = timeit.default_timer()\n",
    "total_time = stop - start_time\n",
    "\n",
    "# output running time in a nice format.\n",
    "mins, secs = divmod(total_time, 60)\n",
    "hours, mins = divmod(mins, 60)\n",
    "\n",
    "sys.stdout.write(\"Total running time: %d:%d:%d.\" % (hours, mins, secs))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf4d54fbd1aa67388c0b0b70ec3753651b0e16d7eeb31ef24b0b3bf91c5c03b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
